{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c35af1-f84a-412d-a59f-dedaf1cc2460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import time \n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "from pyproj import CRS\n",
    "import rasterio\n",
    "import rioxarray\n",
    "from rasterio.enums import Resampling\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f70ce24-e85a-469b-8913-5a49635c57ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For calculating statistical northness and eastness\n",
    "\n",
    "filename_physstates_2d = '/cluster/projects/itk-SINMOD/coral-mapping/midnor/samp_2D_jan_jun.nc'\n",
    "physstates_2d = Dataset(filename_physstates_2d, 'r')\n",
    "gridLons = physstates_2d.variables['gridLons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48fb4625-cfb2-4c82-a8ca-37acd3fba5cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<string>:21\u001b[0;36m\u001b[0m\n\u001b[0;31m    if output_path is not None:\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#Create bottom-features \n",
    "\n",
    "def process_bottom_layer(filepath,\n",
    "    variable_name,\n",
    "    gridLons=None, #To calculate statistical northness and eastness\n",
    "    output_path=None\n",
    "):\n",
    "     \"\"\"\n",
    "    Process bottom layer data for a specified variable in a NetCDF file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Path to the NetCDF file.\n",
    "    - variable_name (str): Name of the variable to process.\n",
    "    - output_path (str): Path to save the processed file (optional). If None, the result is not saved.\n",
    "    \n",
    "    Returns:\n",
    "    - xarray.DataArray: The time-averaged bottom layer data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if output path is valid\n",
    "    if output_path is not None:\n",
    "        output_dir = os.path.dirname(output_path)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        elif not os.access(output_dir, os.W_OK):\n",
    "            raise PermissionError(f\"Write permission denied for the directory: {output_dir}\")\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    ds = xr.open_dataset(file_path)\n",
    "\n",
    "    print(f\"\\nAccessed the dataset after {time.time() - time_start:.2f} seconds\")\n",
    "\n",
    "   for dim in [\"time\", \"xc\", \"yc\"]:\n",
    "        if dim in ds.dims:  \n",
    "            ds = ds.dropna(dim=dim, how=\"any\")\n",
    "\n",
    "    #Extract the  desired variable\n",
    "    if variable_name == \"current_speed\":\n",
    "        data_var = ds[\"u_velocity\"]\n",
    "\n",
    "    elif variable_name == \"statistical_northness\" or variable_name == \"statistical_eastness\":\n",
    "        data_var = ds[\"u_velocity\"]\n",
    "\n",
    "    else:\n",
    "        data_var = ds[variable_name]\n",
    "    \n",
    "    #Extract the first time step\n",
    "    time_slice = data_var.isel(time=0)\n",
    "    \n",
    "    #Create a mask for valid values in first time step\n",
    "    valid_mask = ~time_slice.isnull()\n",
    "    \n",
    "    #Find the index of the bottom-most valid layer for each (yc, xc)\n",
    "    #Subtract 1 to get the correct index for the bottom layer\n",
    "    bottom_layer_idx = valid_mask.argmin(dim=\"zc\") - 1\n",
    "\n",
    "    #Ensure bottom_layer_idx does not go negative (e.g., if all values are invalid in a column)\n",
    "    bottom_layer_idx = bottom_layer_idx.clip(min=0)\n",
    "\n",
    "    #Extract the bottom layer data across all time steps\n",
    "    if variable_name == \"current_speed\":\n",
    "        bottom_layer_data = (data_var.isel(zc=bottom_layer_idx)**2 + ds[\"v_velocity\"].isel(zc=bottom_layer_idx)**2)**0.5\n",
    "        \n",
    "    elif variable_name == \"statistical_northness\" or variable_name == \"statistical_eastness\":\n",
    "        longitude_of_projection_origin = ds[\"grid_mapping\"].attrs[\"longitude_of_projection_origin\"]\n",
    "        theta = gridLons - longitude_of_projection_origin\n",
    "        eastward_velocity = data_var.isel(zc=bottom_layer_idx)* np.cos(np.deg2rad(theta)) - ds[\"v_velocity\"].isel(zc=bottom_layer_idx)*np.sin(np.deg2rad(theta))\n",
    "        northward_velocity = data_var.isel(zc=bottom_layer_idx)* np.sin(np.deg2rad(theta)) + ds[\"v_velocity\"].isel(zc=bottom_layer_idx)* np.cos(np.deg2rad(theta))\n",
    "        aspect = np.arctan2(eastward_velocity, northward_velocity)\n",
    "\n",
    "        if variable_name == 'statistical_eastness':\n",
    "            bottom_layer_data = np.sin(aspect)\n",
    "        else:\n",
    "            bottom_layer_data = np.cos(aspect)\n",
    "        \n",
    "    else:\n",
    "        bottom_layer_data = data_var.isel(zc=bottom_layer_idx)\n",
    "        \n",
    "    ds.close()\n",
    "\n",
    "    print(f\"\\nExtracted the bottom layer data after {time.time() - time_start:.2f} seconds.\\n\\nStarting computation of statistics...\")\n",
    "\n",
    "    if variable_name == 'temperature_sundahl':\n",
    "        #Calculate Min(mean March-May) and Max(mean Oct-Dec)\n",
    "\n",
    "        min_march_may = #\n",
    "        max_oct_dec = #\n",
    "        print(f\"\\nComputed statistics after {time.time() - time_start:.2f} seconds\")\n",
    "\n",
    "        #Create a new DataArray with the (min, max) and explicitly define the 'stat' dimension\n",
    "        #Concatenate \n",
    "        stats_array = xr.concat([min_march_may, max_oct_dec], dim=\"stat\").rename(f\"{variable_name}_features\")\n",
    "        stats_array = stats_array.assign_coords(stat=[\"min_(mean_march_may)\", \"max_(mean_oct_dec)\"])\n",
    "\n",
    "\n",
    "    else:\n",
    "        #Calculate statistics across time\n",
    "        time_avg_bottom_layer = bottom_layer_data.mean(dim=\"time\", skipna=True)\n",
    "\n",
    "        #Calculate both 10th and 90th percentiles\n",
    "        time_percentiles = bottom_layer_data.quantile([0.1, 0.9], dim=\"time\", skipna=True)\n",
    "    \n",
    "        print(f\"\\nComputed statistics after {time.time() - time_start:.2f} seconds\")\n",
    "    \n",
    "        #Create a new DataArray with the (mean, 10th, 90th) percentiles and explicitly define the 'stat' dimension\n",
    "        #Concatenate mean and percentiles in one line, drop 'quantile' and concatenate all together\n",
    "        stats_array = xr.concat([time_avg_bottom_layer, time_percentiles.sel(quantile=0.1).drop_vars(\"quantile\"), time_percentiles.sel(quantile=0.9).drop_vars(\"quantile\")], dim=\"stat\").rename(f\"{variable_name}_features\")\n",
    "        stats_array = stats_array.assign_coords(stat=[\"mean\", \"10th_percentile\", \"90th_percentile\"])\n",
    "\n",
    "    #Save to output file if specified\n",
    "    if output_path:\n",
    "        stats_array.to_netcdf(output_path, mode='w')\n",
    "\n",
    "    return stats_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f844939f-b80b-4ced-b866-954f59644623",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run for desired features\n",
    "\n",
    "#Run on temperature data\n",
    "#process_bottom_layer_no_dask(\"/cluster/projects/itk-SINMOD/coral-mapping/midnor/PhysStates_2019.nc\", \"temperature\", output_path=\"/cluster/home/haroldh/coral-mapping/processed_data/features/temperature_bottom_features.nc\")\n",
    "\n",
    "#process_bottom_layer_no_dask(\"/cluster/projects/itk-SINMOD/coral-mapping/midnor/PhysStates_2019.nc\", \"salinity\", output_path=\"/cluster/home/haroldh/coral-mapping/processed_data/features/salinity_bottom_features.nc\")\n",
    "\n",
    "#process_bottom_layer_no_dask(\"/cluster/projects/itk-SINMOD/coral-mapping/midnor/PhysStates_2019.nc\", \"current_speed\", output_path=\"/cluster/home/haroldh/coral-mapping/processed_data/features/current_speed_bottom_features.nc\")\n",
    "\n",
    "#For Sundahl's definiton of temperature\n",
    "#process_bottom_layer_no_dask(\"filepath\", \"temperature_sundahl\", output_path=\"\")\n",
    "\n",
    "\n",
    "#Run on statistical northness\n",
    "#process_bottom_layer_no_dask(\"/cluster/projects/itk-SINMOD/coral-mapping/midnor/PhysStates_2019.nc\", \"statistical_northness\", gridLons, output_path=\"/cluster/home/haroldh/coral-mapping/processed_data/features/statistical_northness_features.nc\")\n",
    "\n",
    "# process_bottom_layer_no_dask(\"/cluster/projects/itk-SINMOD/coral-mapping/midnor/PhysStates_2019.nc\", \"statistical_eastness\", gridLons, output_path=\"/cluster/home/haroldh/coral-mapping/processed_data/features/statistical_eastness_features.nc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d270f64e-52bb-4c28-a905-528720df30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Align SINMOD and EMOD data into same format. Returns a big array of all the features including EMOD and SINMOD, \n",
    "#with the same grid spacing and EPRSG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df8e133-b9c7-4545-8d21-fa8052e4710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1: Load and combine all bottom features \n",
    "\n",
    "#Load the SINMOD NetCDF file\n",
    "sinmod_file = '/cluster/projects/itk-SINMOD/coral-mapping/midnor/PhysStates_2019.nc'\n",
    "temp_file = 'processed_data/features/temperature_bottom_features.nc'\n",
    "salinity_file = 'processed_data/features/salinity_bottom_features.nc'\n",
    "current_speed_file = 'processed_data/features/current_speed_bottom_features.nc'\n",
    "statistical_northness_file = 'processed_data/features/statistical_northness_features.nc'\n",
    "statistical_eastness_file = 'processed_data/features/statistical_eastness_features.nc'\n",
    "\n",
    "ds = xr.open_dataset(sinmod_file)\n",
    "temp_ds = xr.open_dataset(temp_file)\n",
    "salinity_ds = xr.open_dataset(salinity_file)\n",
    "current_speed_ds = xr.open_dataset(current_speed_file)\n",
    "statistical_northness_ds = xr.open_dataset(statistical_northness_file)\n",
    "statistical_eastness_ds = xr.open_dataset(statistical_eastness_file)\n",
    "\n",
    "SINMOD_features = xr.Dataset({\n",
    "    'bottom_temperature_features': temp_ds[\"temperature_features\"],\n",
    "    'bottom_salinity_features': salinity_ds[\"salinity_features\"],\n",
    "    'bottom_current_features': current_speed_ds[\"current_speed_features\"],\n",
    "    'bottom_statistical_northness_features': statistical_northness[\"statistical_northness_features\"],\n",
    "    'bottom_statistical_eastness_features': statistical_eastness[\"statistical_eastness_features\"],\n",
    "})\n",
    "\n",
    "temp_ds.close()\n",
    "salinity_ds.close()\n",
    "current_speed_ds.close()\n",
    "statistical_northness_ds.close()\n",
    "statistical_eastness_ds.close()\n",
    "ds.close()\n",
    "\n",
    "del temp_ds\n",
    "del salinity_ds\n",
    "del current_speed_ds\n",
    "del statistical_northness_ds\n",
    "del statistical_eastness_ds\n",
    "\n",
    "\n",
    "SINMOD_features = SINMOD_features.reset_coords(drop=True)\n",
    "\n",
    "print(SINMOD_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b215426-0941-44ff-a336-6ab662c7259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2: Get null land points as verification\n",
    "null_land_points = ds['temperature'].isel(time=0, zc=0).isnull().sum().values\n",
    "\n",
    "ocean_points = ds['temperature'].isel(time=0, zc=0).notnull().sum().values\n",
    "\n",
    "print(f\"Null land points: {null_land_points}\")\n",
    "print(f\"Ocean points: {ocean_points}\")\n",
    "print(f\"Total points: {null_land_points + ocean_points}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ecbb9-fabf-4293-a933-2ea8f94bfa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3: Get the SINMOD crs and attach it to the dataset\n",
    "\n",
    "def obtain_sinmod_crs(PhysStates_data):\n",
    "    grid_mapping = PhysStates_data['grid_mapping']  #Replace 'grid_mapping' with the correct variable name if different\n",
    "    grid_attrs = grid_mapping.attrs  \n",
    "\n",
    "    #Print horizontal resolution if available\n",
    "    horizontal_resolution = grid_attrs.get('horizontal_resolution', 'unknown')\n",
    "    print(f\"\\nHorizontal resolution: {horizontal_resolution} meters\")\n",
    "\n",
    "    #Construct the CRS using the attributes\n",
    "    crs_sinmod = CRS.from_proj4(\n",
    "        f\"+proj=stere \"\n",
    "        f\"+lat_0={grid_attrs['latitude_of_projection_origin']} \"\n",
    "        f\"+lat_ts={grid_attrs['standard_parallel']} \"\n",
    "        f\"+lon_0={grid_attrs['straight_vertical_longitude_from_pole']} \"\n",
    "        f\"+x_0={grid_attrs['false_easting']} \"\n",
    "        f\"+y_0={grid_attrs['false_northing']} \"\n",
    "        f\"+a={grid_attrs['semi_major_axis']} \"\n",
    "        f\"+b={grid_attrs['semi_minor_axis']} \"\n",
    "        f\"+units=m +no_defs\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nSINMOD CRS: {crs_sinmod}\")\n",
    "    return crs_sinmod\n",
    "\n",
    "midnor_crs = obtain_sinmod_crs(ds)\n",
    "\n",
    "del(ds)\n",
    "\n",
    "#Attach the crs to the SINMOD dataset\n",
    "SINMOD_features = SINMOD_features.rio.write_crs(midnor_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eacb2a-3cbb-42d2-ba62-aa84ee296612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4: Align the SINMOD data with the bathymetry\n",
    "\n",
    "tif_file = 'raw_data/EMOD-tifs/bathymetry_32N_Clip_sample.tif'\n",
    "\n",
    "tif_files = ['raw_data/EMOD-tifs/aspect_cos.tif', 'raw_data/EMOD-tifs/aspect_sin.tif', 'raw_data/EMOD-tifs/bathymetry_32N_Clip_sample.tif', 'raw_data/EMOD-tifs/broad_BPI_std.tif',\n",
    "             'raw_data/EMOD-tifs/fine_BPI_std.tif', 'raw_data/EMOD-tifs/log_ruggedness_1.tif', 'raw_data/EMOD-tifs/slope.tif']\n",
    "\n",
    "\n",
    "def align_SINMOD_and_bathymetry(SINMOD_features, tif_file, resampling=Resampling.bilinear):\n",
    "        \n",
    "    with rioxarray.open_rasterio(tif_file) as tif:\n",
    "\n",
    "        #Remove the band dimension from the tif data\n",
    "        if 'band' in tif.dims:\n",
    "            tif = tif.isel(band=0)\n",
    "\n",
    "        SINMOD_features_reprojected = SINMOD_features.rio.reproject_match(tif, resampling=resampling)\n",
    "\n",
    "        print(SINMOD_features_reprojected.rio.bounds())\n",
    "\n",
    "         Make mask of NaN SINMOD values\n",
    "        sinmod_mask = SINMOD_features_reprojected['bottom_temperature_features'][0].isnull()\n",
    "\n",
    "        #Apply the mask to the EMOD data\n",
    "        tif = tif.where(~sinmod_mask, np.nan)\n",
    "\n",
    "        valid_mask = SINMOD_features_reprojected['bottom_temperature_features'][0].notnull()\n",
    "\n",
    "        valid_columns = valid_mask.any(dim=\"y\")  \n",
    "        min_col = valid_columns.argmax().item()  #First non-NaN column from the left\n",
    "        max_col = valid_columns.shape[0] - valid_columns[::-1].argmax().item() - 1  #First non-NaN column from the right\n",
    "\n",
    "        #Find the first valid row (non-NaN) from the top (min row index)\n",
    "        valid_rows = valid_mask.any(dim=\"x\")  #Check for valid values in each row\n",
    "        min_row = valid_rows.argmax().item()  #First non-NaN row from the top\n",
    "        max_row = valid_rows.shape[0] - valid_rows[::-1].argmax().item() - 1  #Adjust for reverse indexing\n",
    "\n",
    "        #Slice the raster to the bounding box of valid data\n",
    "        clipped_SINMOD_features = SINMOD_features_reprojected.isel(x=slice(min_col, max_col + 1), y=slice(min_row, max_row + 1))\n",
    "        \n",
    "        clipped_tif = tif.rio.clip_box(minx=clipped_SINMOD_features.rio.bounds()[0]+1, \n",
    "                                        miny=clipped_SINMOD_features.rio.bounds()[1], \n",
    "                                        maxx=clipped_SINMOD_features.rio.bounds()[2], \n",
    "                                        maxy=clipped_SINMOD_features.rio.bounds()[3])\n",
    "        \n",
    "        clipped_tif = clipped_tif.reset_coords(drop=True)\n",
    "\n",
    "    return clipped_SINMOD_features, clipped_tif\n",
    "\n",
    "SINMOD_features_reprojected, tif = align_SINMOD_and_bathymetry(SINMOD_features, tif_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6197ff02-2aaf-486d-87fb-1b51e8e7fd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5: Handle missing values in the SINMOD dataset, make sure NaNs are consistent throughout\n",
    "\n",
    "#Check that all features have the same null points\n",
    "assert (SINMOD_features_reprojected['bottom_temperature_features'].isnull() == \n",
    "    SINMOD_features_reprojected['bottom_salinity_features'].isnull()).all()\n",
    "assert (SINMOD_features_reprojected['bottom_temperature_features'].isnull() == \n",
    "    SINMOD_features_reprojected['bottom_current_features'].isnull()).all()\n",
    "\n",
    "#Check that if one is not null, then they are all not null\n",
    "assert (SINMOD_features_reprojected['bottom_temperature_features'].notnull() == \n",
    "    SINMOD_features_reprojected['bottom_salinity_features'].notnull()).all()\n",
    "assert (SINMOD_features_reprojected['bottom_temperature_features'].notnull() == \n",
    "    SINMOD_features_reprojected['bottom_current_features'].notnull()).all()\n",
    "\n",
    "#Ensure that tif is NaN everywhere SINMOD_features_reprojected is NaN\n",
    "assert np.all(np.isnan(tif.values) == np.isnan(SINMOD_features_reprojected['bottom_temperature_features'][0].values))\n",
    "\n",
    "#Ensure that tif is non-Nan everywhere SINMOD_features_reprojected is non-NaN\n",
    "assert np.all(np.isfinite(tif.values) == np.isfinite(SINMOD_features_reprojected['bottom_temperature_features'][0].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8c67c0-c77e-4ea2-8af1-8f1e8cd12836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6: Check tif properties\n",
    "def check_tif_properties(tif_files):\n",
    "\n",
    "    with rioxarray.open_rasterio(tif_files[0]) as tif:\n",
    "        print(\"\\n File to compare is: \", tif_files[0])\n",
    "        ref_bounds, ref_crs, ref_res, ref_dims = tif.rio.bounds(), tif.rio.crs, tif.rio.resolution(), tif.shape\n",
    "\n",
    "        #Check if all files match the reference properties\n",
    "        for tif_file in tif_files[1:]:\n",
    "            print(\"\\n Checking file: \", tif_file)\n",
    "            with rioxarray.open_rasterio(tif_file) as tif:\n",
    "                if not (tif.rio.bounds() == ref_bounds and\n",
    "                        tif.rio.crs == ref_crs and\n",
    "                        tif.rio.resolution() == ref_res and\n",
    "                        tif.shape == ref_dims):\n",
    "                    print(f\"Mismatch found in {tif_file}\")\n",
    "                    print(f\"Expected bounds: {ref_bounds}, Found: {tif.rio.bounds()}\")\n",
    "                    print(f\"Expected CRS: {ref_crs}, Found: {tif.rio.crs}\")\n",
    "                    print(f\"Expected resolution: {ref_res}, Found: {tif.rio.resolution()}\")\n",
    "                    print(f\"Expected dimensions: {ref_dims}, Found: {tif.shape}\")\n",
    "                    continue\n",
    "                print(\"Properties match.\")\n",
    "\n",
    "check_tif_properties(tif_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ada8651-b62c-41ac-947b-889610dd415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7: Repeat for all the EMOD tifs and create a dataset for all the clipped tif files\n",
    "\n",
    "EMOD_features = xr.Dataset()\n",
    "\n",
    "for file in tif_files:\n",
    "    SINMOD_temp, file_tif = align_SINMOD_and_bathymetry(SINMOD_features, file)\n",
    "    \n",
    "    #Add the clipped tif as a new variable in the dataset\n",
    "    file_name = file.split(\"/\")[-1].split(\".\")[0] + \"_clipped\"\n",
    "    var_name = file.split(\"/\")[-1].split(\".\")[0]\n",
    "    EMOD_features[var_name] = file_tif\n",
    "\n",
    "    file_tif.to_netcdf(f'processed_data/features/{file_name}.nc', mode='w')\n",
    "\n",
    "    # Clear memory of file_tif and SINMOD_temp\n",
    "    del file_tif\n",
    "    del SINMOD_temp\n",
    "\n",
    "EMOD_features = EMOD_features.reset_coords(drop=True)\n",
    "EMOD_features.to_netcdf('processed_data/features/EMOD_features.nc', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a27c2b-688b-4d0b-bb40-143780108c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8: Create current_aspect_angle feature. Absolute difference between the current direction and the depth aspect direction.\n",
    "\n",
    "aspect_bathymetry = EMOD_features['aspect_cos_clipped']\n",
    "aspect_current = SINMOD_features_reprojected['bottom_statistical_northness_features'].sel(stat='mean')\n",
    "\n",
    "SINMOD_features_reprojected['current_aspect_angle'] = abs(np.arccos(aspect_current) - np.arccos(aspect_bathymetry)) * 180 / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ca226a-1d68-40c4-88db-aff2f60a4aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9: Standardizing the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Standardize the features\n",
    "temperature_standardized = scaler.fit_transform(SINMOD_features_reprojected['temperature'].reshape(-1, 1)).reshape(SINMOD_features_reprojected['temperature'].shape)\n",
    "salinity_standardized = scaler.fit_transform(SINMOD_features_reprojected['salinity'].reshape(-1, 1)).reshape(SINMOD_features_reprojected['salinity'].shape)\n",
    "#repeat for all features\n",
    "\n",
    "#Print the mean and standard deviation of the standardised features to verify\n",
    "print(f\"Standardised Temperature - Mean: {temperature_standardized.mean():.2f}, Std Dev: {temperature_standardized.std():.2f}\")\n",
    "print(f\"Standardised Salinity - Mean: {salinity_standardized.mean():.2f}, Std Dev: {salinity_standardized.std():.2f}\")\n",
    "#repeat for all features\n",
    "\n",
    "SINMOD_features_reprojected['temperature'] = temperature_standardized\n",
    "SINMOD_features_reprojected['salinity'] = salinity_standardized\n",
    "#repeat for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d33051-ea00-4002-b2f1-2bea294029a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10: Saving the reprojected and standardized data\n",
    "output_file = 'processed_data/features/ready-for-training/SINMOD_bottom_features.nc'\n",
    "\n",
    "SINMOD_features_reprojected.to_netcdf(output_file, mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
