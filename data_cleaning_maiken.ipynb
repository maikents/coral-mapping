{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting necessary SINMOD data\n",
    "\n",
    "Extracting more than a few time steps will take a while and potentially cause crashing. Then we will need to run on IDUN. Can set up via VS code ssh.\n",
    "\n",
    "We will now:\n",
    "- Look at a few data sets to check the numbers make sense\n",
    "- Standardise and normalise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time                 No units\n",
      "grid_mapping         No units\n",
      "LayerDepths          m\n",
      "xc                   meter\n",
      "yc                   meter\n",
      "zc                   m\n",
      "depth                m\n",
      "DXxDYy               m2\n",
      "u_velocity           m/s\n",
      "v_velocity           m/s\n",
      "elevation            m\n",
      "temperature          degC\n",
      "salinity             psu\n",
      "ice_thickness        m\n",
      "ice_compactness      -\n",
      "salinity_ice         psu\n"
     ]
    }
   ],
   "source": [
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# Importing SINMOD data\n",
    "filename_PhysStates = 'PhysStates.nc'\n",
    "\n",
    "PhysStates_data = Dataset(filename_PhysStates, 'r')\n",
    "\n",
    "# Looking at our list of available variables\n",
    "variables_list = list(PhysStates_data.variables.keys())\n",
    "for variable in variables_list:\n",
    "    units = PhysStates_data.variables[variable].units if 'units' in PhysStates_data.variables[variable].ncattrs() else 'No units'\n",
    "    print(f\"{variable:<20} {units}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINMOD grid dimensions:\n",
      "xc shape: (300,)\n",
      "yc shape: (235,)\n",
      "zc shape: (25,)\n",
      "\n",
      "Temperature data shape: (25, 235, 300)\n",
      "Mean temperature:\t1.64\n",
      "Max temperature:\t10.86\n",
      "Min temperature:\t-1.80\n",
      "\n",
      "Salinity data shape:\t(25, 235, 300)\n",
      "Mean salinity:\t\t34.23\n",
      "Max salinity:\t\t37.26\n",
      "Min salinity:\t\t0.10\n"
     ]
    }
   ],
   "source": [
    "# Extracting all the map dimensions, we can extract both ways, I don't think it matters\n",
    "xc = PhysStates_data.variables['xc'][:]  # x-coordinates (meters)\n",
    "yc = PhysStates_data.variables['yc'][:]  # y-coordinates (meters)\n",
    "zc = PhysStates_data['LayerDepths'][:]  # z-coordinates (meters)\n",
    "\n",
    "# Now checking temperature data matches what we expect from the dimensions\n",
    "# Extracting temperature at t = 0, and check the dimensions\n",
    "temperature_var = PhysStates_data.variables['temperature']\n",
    "temperature = temperature_var[0,:,:,:]\n",
    "print(\"SINMOD grid dimensions:\")\n",
    "print(f\"xc shape: {xc.shape}\")\n",
    "print(f\"yc shape: {yc.shape}\")\n",
    "print(f\"zc shape: {zc.shape}\")\n",
    "\n",
    "print(f\"\\nTemperature data shape: {temperature.shape}\")\n",
    "# Now checking mean, max and min temperature to see if it makes sense\n",
    "print(f\"Mean temperature:\\t{temperature.mean():.2f}\")\n",
    "print(f\"Max temperature:\\t{temperature.max():.2f}\")\n",
    "print(f\"Min temperature:\\t{temperature.min():.2f}\")\n",
    "\n",
    "# Repeating for salinity\n",
    "salinity_var = PhysStates_data.variables['salinity']\n",
    "salinity = salinity_var[0,:,:,:]\n",
    "\n",
    "print(f\"\\nSalinity data shape:\\t{salinity.shape}\")\n",
    "print(f\"Mean salinity:\\t\\t{salinity.mean():.2f}\")\n",
    "print(f\"Max salinity:\\t\\t{salinity.max():.2f}\")\n",
    "print(f\"Min salinity:\\t\\t{salinity.min():.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Temperature - Mean: 0.00, Std Dev: 1.00\n",
      "Standardized Salinity - Mean: 0.00, Std Dev: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Many options for what sort of standardisation we want here, but a simple one:\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize the temperature and salinity data\n",
    "temperature_standardized = scaler.fit_transform(temperature.reshape(-1, temperature.shape[-1])).reshape(temperature.shape)\n",
    "salinity_standardized = scaler.fit_transform(salinity.reshape(-1, salinity.shape[-1])).reshape(salinity.shape)\n",
    "\n",
    "# Print the mean and standard deviation of the standardized data to verify\n",
    "print(f\"Standardized Temperature - Mean: {temperature_standardized.mean():.2f}, Std Dev: {temperature_standardized.std():.2f}\")\n",
    "print(f\"Standardized Salinity - Mean: {salinity_standardized.mean():.2f}, Std Dev: {salinity_standardized.std():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeating for Biostates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time                 No units\n",
      "grid_mapping         No units\n",
      "LayerDepths          m\n",
      "xc                   meter\n",
      "yc                   meter\n",
      "zc                   m\n",
      "depth                m\n",
      "DXxDYy               m2\n",
      "nitrate              mmmol N m-3\n",
      "silicate             mmmol N m-3\n",
      "ammonium             mmmol N m-3\n",
      "diatoms              mmmol N m-3\n",
      "flagellates          mmmol N m-3\n",
      "ciliates             mmmol N m-3\n",
      "HNANO                mmmol N m-3\n",
      "bacteria             mmmol N m-3\n",
      "calanus_finmarchicus gC m-2\n",
      "calanus_glacialis    gC m-2\n",
      "detritus_slow        mmmol N m-3\n",
      "detritus_fast        mmmol N m-3\n",
      "DOC                  mmmol N m-3\n",
      "cDOM                 m-1\n",
      "silicate_detritus    mmmol N m-3\n",
      "sediment_Si          mmmol Si m-2\n",
      "sediment_N           mmmol N m-2\n"
     ]
    }
   ],
   "source": [
    "# Importing BioStates data\n",
    "filename_BioStates = 'BioStates.nc'\n",
    "\n",
    "BioStates_data = Dataset(filename_BioStates, 'r')\n",
    "\n",
    "\n",
    "# Looking at our list of available variables\n",
    "variables_list_bio = list(BioStates_data.variables.keys())\n",
    "for variable in variables_list_bio:\n",
    "    units = BioStates_data.variables[variable].units if 'units' in BioStates_data.variables[variable].ncattrs() else 'No units'\n",
    "    print(f\"{variable:<20} {units}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINMOD grid dimensions:\n",
      "xc shape: (300,)\n",
      "yc shape: (235,)\n",
      "zc shape: (25,)\n",
      "\n",
      "Nitrate data shape:\t(25, 235, 300)\n",
      "Mean nitrate:\t\t11.75\n",
      "Max nitrate:\t\t76.16\n",
      "Min nitrate:\t\t0.10\n",
      "\n",
      "Silicate data shape:\t(25, 235, 300)\n",
      "Mean silicate:\t\t7.53\n",
      "Max silicate:\t\t99.98\n",
      "Min silicate:\t\t0.10\n"
     ]
    }
   ],
   "source": [
    "# Extracting all the map dimensions, we can extract both ways, I don't think it matters\n",
    "xc_bio = BioStates_data.variables['xc'][:]  # x-coordinates (meters)\n",
    "yc_bio = BioStates_data.variables['yc'][:]  # y-coordinates (meters)\n",
    "zc_bio = BioStates_data['LayerDepths'][:]  # z-coordinates (meters)\n",
    "\n",
    "print(\"SINMOD grid dimensions:\")\n",
    "print(f\"xc shape: {xc_bio.shape}\")\n",
    "print(f\"yc shape: {yc_bio.shape}\")\n",
    "print(f\"zc shape: {zc_bio.shape}\")\n",
    "\n",
    "# Now checking chlorophyll data matches what we expect from the dimensions\n",
    "# Extracting chlorophyll at t = 0, and check the dimensions\n",
    "\"\"\"chlorophyll_var = BioStates_data.variables['chlorophyll']\n",
    "chlorophyll = chlorophyll_var[0,:,:,:]\n",
    "print(\"BioStates grid dimensions:\")\n",
    "print(f\"xc shape: {xc_bio.shape}\")\n",
    "print(f\"yc shape: {yc_bio.shape}\")\n",
    "print(f\"zc shape: {zc_bio.shape}\")\n",
    "\n",
    "print(f\"\\nChlorophyll data shape: {chlorophyll.shape}\")\n",
    "# Now checking mean, max and min chlorophyll to see if it makes sense\n",
    "print(f\"Mean chlorophyll:\\t{chlorophyll.mean():.2f}\")\n",
    "print(f\"Max chlorophyll:\\t{chlorophyll.max():.2f}\")\n",
    "print(f\"Min chlorophyll:\\t{chlorophyll.min():.2f}\")\"\"\"\n",
    "\n",
    "# Repeating for nitrate\n",
    "nitrate_var = BioStates_data.variables['nitrate']\n",
    "nitrate = nitrate_var[0,:,:,:]\n",
    "\n",
    "print(f\"\\nNitrate data shape:\\t{nitrate.shape}\")\n",
    "print(f\"Mean nitrate:\\t\\t{nitrate.mean():.2f}\")\n",
    "print(f\"Max nitrate:\\t\\t{nitrate.max():.2f}\")\n",
    "print(f\"Min nitrate:\\t\\t{nitrate.min():.2f}\")\n",
    "\n",
    "# Repeating for silicate\n",
    "silicate_var = BioStates_data.variables['silicate']\n",
    "silicate = silicate_var[0,:,:,:]\n",
    "\n",
    "print(f\"\\nSilicate data shape:\\t{silicate.shape}\")\n",
    "print(f\"Mean silicate:\\t\\t{silicate.mean():.2f}\")\n",
    "print(f\"Max silicate:\\t\\t{silicate.max():.2f}\")\n",
    "print(f\"Min silicate:\\t\\t{silicate.min():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Nitrate - Mean: -0.00, Std Dev: 1.00\n",
      "Standardized Silicate - Mean: 0.00, Std Dev: 1.00\n"
     ]
    }
   ],
   "source": [
    "#Standardizing\n",
    "\n",
    "# Standardize the nitrate and silicate data\n",
    "nitrate_standardized = scaler.fit_transform(nitrate.reshape(-1, nitrate.shape[-1])).reshape(nitrate.shape)\n",
    "silicate_standardized = scaler.fit_transform(silicate.reshape(-1, silicate.shape[-1])).reshape(silicate.shape)\n",
    "\n",
    "# Print the mean and standard deviation of the standardized data to verify\n",
    "print(f\"Standardized Nitrate - Mean: {nitrate_standardized.mean():.2f}, Std Dev: {nitrate_standardized.std():.2f}\")\n",
    "print(f\"Standardized Silicate - Mean: {silicate_standardized.mean():.2f}, Std Dev: {silicate_standardized.std():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing coral reef data\n",
    "\n",
    "# gml_file_coral_reefs = \"./KystOgFiskeri_50_Trondelag_25832_Korallrev_GML.gml\"\n",
    "#gml_file_coral_reefs = \"KystOgFiskeri_50_Trondelag_25833_Korallrev_GML.gml\"\n",
    "gml_file_coral_reefs = \"KystOgFiskeri_50_Trondelag_25832_Korallrev_GML.gml\"\n",
    "\n",
    "gdf_coral_reefs = gpd.read_file(gml_file_coral_reefs)\n",
    "\n",
    "# Not sure this is necessary since all the naturtypeNavn are the same\n",
    "# unique_naturtypeNavn = gdf_coral_reefs['naturtypeNavn'].unique()\n",
    "# print(unique_naturtypeNavn)\n",
    "coral_data = gdf_coral_reefs[gdf_coral_reefs['naturtypeNavn'] == 'Korallforekomster']\n",
    "\n",
    "# I think it's already a dataframe, so also unnecessary\n",
    "#coral_df = pd.DataFrame(coral_data)\n",
    "\n",
    "\n",
    "#coral_location_df = coral_df[['lengdegrad', 'breddegrad']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coral data crs:\n",
      "EPSG:25832\n",
      "---------\n",
      "Coral data shape total:\n",
      "(104, 21)\n",
      "Coral data Trøndelag shape:\n",
      "(104, 21)\n",
      "Coral data Rogaland shape:\n",
      "(91, 21)\n",
      "Coral data Vestland shape:\n",
      "(232, 21)\n",
      "-----------\n",
      "Coral data Nordland shape:\n",
      "(461, 21)\n",
      "Coral reef Finnmark shape:\n",
      "(49, 21)\n",
      "Coral reef Troms shape:\n",
      "(36, 21)\n",
      "Coral reef Barents shape:\n",
      "(98, 21)\n",
      "Coral reef Norskehavet shape:\n",
      "(647, 21)\n",
      "-----------\n",
      "EPSG:25833\n",
      "EPSG:25833\n",
      "EPSG:25833\n",
      "EPSG:25833\n",
      "EPSG:25832\n",
      "Variables in coral data:\n",
      "gml_id\n",
      "lokalId\n",
      "navnerom\n",
      "verifiseringsdato\n",
      "produkt\n",
      "versjon\n",
      "målemetode\n",
      "nøyaktighet\n",
      "medium\n",
      "opphav\n",
      "minimumsdybde\n",
      "maksimumsdybde\n",
      "naturtype\n",
      "naturtypeNavn\n",
      "kildeNavn\n",
      "observasjonsMetode\n",
      "observasjonsSted\n",
      "observasjonsSlutt\n",
      "lengdegrad\n",
      "breddegrad\n",
      "geometry\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "# Importing coral reef data from more areas\n",
    "gml_file_coral_reefs_trondelag = \"KystOgFiskeri_50_Trondelag_25832_Korallrev_GML.gml\"\n",
    "gml_file_coral_reefs_more_romsdal = \"KystOgFiskeri_15_More_og_Romsdal_25832_Korallrev_GML.gml\"\n",
    "gml_file_coral_reefs_vestland = \"KystOgFiskeri_46_Vestland_25832_Korallrev_GML.gml\"\n",
    "\n",
    "gml_file_coral_reefs_nordland = \"KystOgFiskeri_18_Nordland_25833_Korallrev_GML.gml\"\n",
    "gml_file_coral_reefs_finnmark = \"KystOgFiskeri_56_Finnmark_25833_Korallrev_GML.gml\"\n",
    "gml_file_coral_reefs_troms = \"KystOgFiskeri_55_Troms_25833_Korallrev_GML.gml\"\n",
    "gml_file_coral_reefs_barents = \"KystOgFiskeri_64_Barentshavet_vest_25833_Korallrev_GML.gml\"\n",
    "gml_file_coral_reefs_norskehavet = \"KystOgFiskeri_63_Norskehavet_25832_Korallrev_GML.gml\"\n",
    "\n",
    "gdf_coral_reefs_trondelag = gpd.read_file(gml_file_coral_reefs_trondelag)\n",
    "gdf_coral_reefs_more_romsdal = gpd.read_file(gml_file_coral_reefs_more_romsdal)\n",
    "gdf_coral_reefs_vestland = gpd.read_file(gml_file_coral_reefs_vestland)\n",
    "\n",
    "gdf_coral_reefs_nordland = gpd.read_file(gml_file_coral_reefs_nordland)\n",
    "gdf_coral_reefs_finnmark = gpd.read_file(gml_file_coral_reefs_finnmark)\n",
    "gdf_coral_reefs_troms = gpd.read_file(gml_file_coral_reefs_troms)\n",
    "gdf_coral_reefs_barents = gpd.read_file(gml_file_coral_reefs_barents)\n",
    "gdf_coral_reefs_norskehavet = gpd.read_file(gml_file_coral_reefs_norskehavet)\n",
    "\n",
    "\n",
    "# Combine them into one GeoDataFrame\n",
    "coral_data_EPSG_25832 = pd.concat(\n",
    "    [gdf_coral_reefs_trondelag, gdf_coral_reefs_more_romsdal, gdf_coral_reefs_vestland, gdf_coral_reefs_norskehavet],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "coral_data_EPSG_25832 = gpd.GeoDataFrame(coral_data_EPSG_25832, geometry='geometry')\n",
    "\n",
    "coral_data_EPSG_25833 = pd.concat(\n",
    "    [gdf_coral_reefs_nordland, gdf_coral_reefs_finnmark, gdf_coral_reefs_troms, gdf_coral_reefs_barents],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "coral_data_EPSG_25833 = gpd.GeoDataFrame(coral_data_EPSG_25833, geometry='geometry')\n",
    "\n",
    "print(\"Coral data crs:\")\n",
    "print(coral_data.crs)\n",
    "print(\"---------\")\n",
    "print(\"Coral data shape total:\")\n",
    "print(coral_data.shape)\n",
    "print(\"Coral data Trøndelag shape:\")\n",
    "print(gdf_coral_reefs_trondelag.shape)\n",
    "print(\"Coral data Rogaland shape:\")\n",
    "print(gdf_coral_reefs_more_romsdal.shape)\n",
    "print(\"Coral data Vestland shape:\")\n",
    "print(gdf_coral_reefs_vestland.shape)\n",
    "print(\"-----------\")\n",
    "print(\"Coral data Nordland shape:\")\n",
    "print(gdf_coral_reefs_nordland.shape)\n",
    "print(\"Coral reef Finnmark shape:\")\n",
    "print(gdf_coral_reefs_finnmark.shape)\n",
    "print(\"Coral reef Troms shape:\")\n",
    "print(gdf_coral_reefs_troms.shape)\n",
    "print(\"Coral reef Barents shape:\")\n",
    "print(gdf_coral_reefs_barents.shape)\n",
    "print(\"Coral reef Norskehavet shape:\")\n",
    "print(gdf_coral_reefs_norskehavet.shape)\n",
    "print(\"-----------\")\n",
    "print(gdf_coral_reefs_nordland.crs)\n",
    "print(gdf_coral_reefs_finnmark.crs)\n",
    "print(gdf_coral_reefs_troms.crs)\n",
    "print(gdf_coral_reefs_barents.crs)\n",
    "print(gdf_coral_reefs_norskehavet.crs)\n",
    "\n",
    "coral_data_variables = coral_data.columns\n",
    "print(\"Variables in coral data:\")\n",
    "for variable in coral_data_variables:\n",
    "    print(variable)\n",
    "\n",
    "print(len(coral_data_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables in coral data:\n",
      "gml_id\n",
      "(1718, 6)\n",
      "lokalId\n",
      "(1718, 6)\n",
      "navnerom\n",
      "(1718, 6)\n",
      "verifiseringsdato\n",
      "(1718, 6)\n",
      "produkt\n",
      "(1718, 6)\n",
      "versjon\n",
      "(1718, 6)\n",
      "målemetode\n",
      "(1718, 6)\n",
      "nøyaktighet\n",
      "(1718, 6)\n",
      "medium\n",
      "(1718, 6)\n",
      "opphav\n",
      "(1718, 6)\n",
      "minimumsdybde\n",
      "(1718, 6)\n",
      "maksimumsdybde\n",
      "(1718, 6)\n",
      "naturtype\n",
      "(1718, 6)\n",
      "naturtypeNavn\n",
      "(1718, 6)\n",
      "kildeNavn\n",
      "(1718, 6)\n",
      "observasjonsMetode\n",
      "(1718, 6)\n",
      "observasjonsSted\n",
      "(1718, 6)\n",
      "observasjonsSlutt\n",
      "(1718, 6)\n",
      "lengdegrad\n",
      "(1718, 6)\n",
      "breddegrad\n",
      "(1718, 6)\n",
      "geometry\n",
      "(1718, 6)\n"
     ]
    }
   ],
   "source": [
    "coral_data_variables = coral_data.columns\n",
    "print(\"Variables in coral data:\")\n",
    "for variable in coral_data_variables:\n",
    "    print(variable)\n",
    "\n",
    "    coral_df_combined = pd.concat([coral_data_EPSG_25832[[\"gml_id\", \"nøyaktighet\", \"minimumsdybde\", \"maksimumsdybde\", \"lengdegrad\", \"breddegrad\"]],\n",
    "                            coral_data_EPSG_25833[[\"gml_id\", \"nøyaktighet\", \"minimumsdybde\", \"maksimumsdybde\", \"lengdegrad\", \"breddegrad\"]]],\n",
    "                           ignore_index=True)\n",
    "    print(coral_df_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "coral_df_combined.to_csv(path_or_buf=\"/Users/maikentomren/Documents/prosjektoppgave/plotting git/Illuminating-the-deep---projections-/combined_coral_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "int32 grid_mapping()\n",
      "    grid_mapping_name: polar_stereographic\n",
      "    straight_vertical_longitude_from_pole: 58.0\n",
      "    horizontal_resolution: 20000.0\n",
      "    latitude_of_projection_origin: 90.0\n",
      "    longitude_of_projection_origin: 58.0\n",
      "    standard_parallel: 60.0\n",
      "    origoRef: [0. 0.]\n",
      "    semi_minor_axis: 6370000.0\n",
      "    semi_major_axis: 6370000.0\n",
      "    false_easting: 3900000.0\n",
      "    false_northing: 2570000.0\n",
      "    scale_factor_at_projection_origin: 1.0\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, default _FillValue of -2147483647 used\n"
     ]
    }
   ],
   "source": [
    "# Now to transform the coordinates to the same projection as the SINMOD data\n",
    "\n",
    "from pyproj import CRS, Transformer\n",
    "\n",
    "# Print grid mapping to see what the horizontal resolution is\n",
    "# In the case of gin it is 20km, for nor4km it is 4km\n",
    "grid_mapping = PhysStates_data.variables['grid_mapping']\n",
    "print(grid_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom left corner: 1.3838543498304823 47.09690769440129\n",
      "Bottom right corner: 1.3834756632228211 47.09690769440129\n",
      "Top left corner: 1.3838543498304823 47.10006795515003\n",
      "Top right corner: 1.3834756632228211 47.10006795515003\n",
      "coral_lons range before: 2.6833 11.32001\n",
      "coral_lats range before: 59.57281 67.0133\n",
      "coral_lons range before 33: 8.75218 22.7332\n",
      "coral_lats range before 33: 65.47768 70.9287\n",
      "--------------------------------\n",
      "coral_lons grid-coordinates after: 66.24751269785357 107.00574385691127\n",
      "coral_lats grid-coordinates after: 29.832777330761463 50.65579211631436\n",
      "coral_lons grid-coordinates after 33: 100.06158866585542 136.58459222140908\n",
      "coral_lats grid-coordinates after 33: 38.961115458723505 50.82802951927174\n",
      "Grid dimensions (xc): 300\n",
      "Grid dimensions (yc): 235\n",
      "20000.0 6000000.0\n",
      "20000.0 4700000.0\n"
     ]
    }
   ],
   "source": [
    "# Specifying projection to SINMOD format\n",
    "\n",
    "# Define the Coordinate Reference Systems (CRS) for the coral data\n",
    "# It could be any of these, need to double check: checked, it is \"EUREF89 UTM sone 32, 2d\" (you could choose others as well)\n",
    "crs_wgs84 = CRS.from_epsg(4326)  # WGS84 (lat/lon coordinates)\n",
    "\n",
    "crs_euref89_utm32 = CRS.from_epsg(25832)  # EUREF89 / UTM zone 32N\n",
    "crs_euref89_utm33 = CRS.from_epsg(25833)  # EUREF89 / UTM zone 33N\n",
    "# crs_euref89 = CRS.from_epsg(4258)  # EUREF89 (geographic lat/lon)\n",
    "\n",
    "# SINMOD projection parameters as a custom projection\n",
    "#crs_sinmod = CRS.from_proj4(\"+proj=stere +lat_0=90 +lat_ts=60 +lon_0=58 \"\n",
    "#                            \"+x_0=3900000 +y_0=2570000 +ellps=WGS84 +units=m +no_defs\")\n",
    "\n",
    "crs_sinmod = CRS.from_proj4(\n",
    "    \"+proj=stere +lat_0=90 +lat_ts=60 +lon_0=58 \"\n",
    "    \"+x_0=3900000 +y_0=2570000 +a=6370000 +b=6370000 +units=m +no_defs\"\n",
    ")\n",
    "\n",
    "# Create a transformer to transform from wgs84 (geographic) to SINMOD\n",
    "transformer_wgs84_to_sinmod = Transformer.from_crs(crs_wgs84, crs_sinmod, always_xy=True)\n",
    "\n",
    "#Create a transformer to transform from euref89 to SINMOD\n",
    "transformer_euref89_to_sinmod = Transformer.from_crs(crs_euref89_utm32, crs_sinmod, always_xy=True)\n",
    "\n",
    "transformer_euref89_to_sinmod_33 = Transformer.from_crs(crs_euref89_utm33, crs_sinmod, always_xy=True)\n",
    "\n",
    "\n",
    "#Create a transformer to transform from SINMOD to wgs84\n",
    "transformer_sinmod_to_wgs84 = Transformer.from_crs( crs_sinmod, crs_wgs84, always_xy=True)\n",
    "\n",
    "xc_grid, yc_grid = np.meshgrid(xc, yc)\n",
    "lon_grid, lat_grid = transformer_wgs84_to_sinmod.transform(xc_grid, yc_grid)\n",
    "\n",
    "\n",
    "xc_lon_min, yc_lat_min = transformer_sinmod_to_wgs84.transform(xc.min()/20000, yc.min()/20000)\n",
    "xc_lon_max, yc_lat_max = transformer_sinmod_to_wgs84.transform(xc.max()/20000, yc.max()/20000)\n",
    "\n",
    "print(\"Bottom left corner:\", xc_lon_min, yc_lat_min)\n",
    "print(\"Bottom right corner:\", xc_lon_max, yc_lat_min)\n",
    "print(\"Top left corner:\", xc_lon_min, yc_lat_max)\n",
    "print(\"Top right corner:\", xc_lon_max, yc_lat_max)\n",
    "\n",
    "\n",
    "# Performing projection on coral reef data\n",
    "print(\"coral_lons range before:\", coral_data_EPSG_25832['lengdegrad'].min(), coral_data_EPSG_25832['lengdegrad'].max())\n",
    "print(\"coral_lats range before:\", coral_data_EPSG_25832['breddegrad'].min(), coral_data_EPSG_25832['breddegrad'].max())\n",
    "\n",
    "print(\"coral_lons range before 33:\", coral_data_EPSG_25833['lengdegrad'].min(), coral_data_EPSG_25833['lengdegrad'].max())\n",
    "print(\"coral_lats range before 33:\", coral_data_EPSG_25833['breddegrad'].min(), coral_data_EPSG_25833['breddegrad'].max())\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "# Transform coral coordinates from EUREF89 to SINMOD\n",
    "coral_x, coral_y = transformer_wgs84_to_sinmod.transform(coral_data_EPSG_25832['lengdegrad'], coral_data_EPSG_25832['breddegrad'])\n",
    "\n",
    "coral_x_33, coral_y_33 = transformer_wgs84_to_sinmod.transform(coral_data_EPSG_25833['lengdegrad'], coral_data_EPSG_25833['breddegrad'])\n",
    "\n",
    "# We need to DIVIDE by the resolution of the SINMOD grid to get the grid coordinates\n",
    "# In the case of gin this is 20km\n",
    "coral_x /= 20000\n",
    "coral_y /= 20000\n",
    "\n",
    "coral_x_33 /= 20000\n",
    "coral_y_33 /= 20000\n",
    "\n",
    "\n",
    "# The values after are NOT lat lon, but rather the SINMOD grid coordinates \n",
    "print(\"coral_lons grid-coordinates after:\", coral_x.min(), coral_x.max())\n",
    "print(\"coral_lats grid-coordinates after:\", coral_y.min(), coral_y.max())\n",
    "\n",
    "print(\"coral_lons grid-coordinates after 33:\", coral_x_33.min(), coral_x_33.max())\n",
    "print(\"coral_lats grid-coordinates after 33:\", coral_y_33.min(), coral_y_33.max())\n",
    "\n",
    "# So we expect them to be in the range of the SINMOD grid:\n",
    "print(f\"Grid dimensions (xc): {xc.shape[0]}\")\n",
    "print(f\"Grid dimensions (yc): {yc.shape[0]}\")\n",
    "\n",
    "\n",
    "print(xc.min(), xc.max())\n",
    "print(yc.min(), yc.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot determine common CRS for concatenation inputs, got ['ETRS89 / UTM zone 32N', 'ETRS89 / UTM zone 33N']. Use `to_crs()` to transform geometries to the same CRS before merging.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Combine the two GeoDataFrames\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m coral_data_combined \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcoral_data_EPSG_25832\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoral_data_EPSG_25833\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Drop duplicates based on 'breddegrad' and 'lengdegrad'\u001b[39;00m\n\u001b[1;32m      7\u001b[0m coral_data_unique \u001b[38;5;241m=\u001b[39m coral_data_combined\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbreddegrad\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlengdegrad\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/reshape/concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/internals/concat.py:180\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    177\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_1d_only_ea_dtype(blk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mconcat_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mea_compat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     values \u001b[38;5;241m=\u001b[39m ensure_block_shape(values, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/dtypes/concat.py:83\u001b[0m, in \u001b[0;36mconcat_compat\u001b[0;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[1;32m     80\u001b[0m to_concat_eas \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence[ExtensionArray]\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_concat)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ea_compat_axis:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# We have 1D objects, that don't support axis keyword\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concat_same_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat_eas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_concat_same_type(to_concat_eas)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/geopandas/array.py:1638\u001b[0m, in \u001b[0;36mGeometryArray._concat_same_type\u001b[0;34m(cls, to_concat)\u001b[0m\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;124;03mConcatenate multiple array\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;124;03mExtensionArray\u001b[39;00m\n\u001b[1;32m   1636\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1637\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([ga\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;28;01mfor\u001b[39;00m ga \u001b[38;5;129;01min\u001b[39;00m to_concat])\n\u001b[0;32m-> 1638\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GeometryArray(data, crs\u001b[38;5;241m=\u001b[39m\u001b[43m_get_common_crs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/geopandas/array.py:1737\u001b[0m, in \u001b[0;36m_get_common_crs\u001b[0;34m(arr_seq)\u001b[0m\n\u001b[1;32m   1729\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1730\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRS not set for some of the concatenation inputs. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1731\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting output\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms CRS as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnames[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1732\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(the single non-null crs provided).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1733\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1734\u001b[0m         )\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m crs_not_none[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1737\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot determine common CRS for concatenation inputs, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnames\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1739\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `to_crs()` to transform geometries to the same CRS before merging.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1740\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot determine common CRS for concatenation inputs, got ['ETRS89 / UTM zone 32N', 'ETRS89 / UTM zone 33N']. Use `to_crs()` to transform geometries to the same CRS before merging."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine the two GeoDataFrames\n",
    "coral_data_combined = pd.concat([coral_data_EPSG_25832, coral_data_EPSG_25833], ignore_index=True)\n",
    "\n",
    "# Drop duplicates based on 'breddegrad' and 'lengdegrad'\n",
    "coral_data_unique = coral_data_combined.drop_duplicates(subset=['breddegrad', 'lengdegrad'])\n",
    "\n",
    "# Convert the resulting DataFrame back to a GeoDataFrame if needed\n",
    "coral_data_unique = gpd.GeoDataFrame(coral_data_unique, geometry='geometry')\n",
    "\n",
    "# Print the unique coral data\n",
    "print(coral_data_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_xc_old = 400\n",
    "grid_yc_old = 350\n",
    "\n",
    "grid_xc_new = 300\n",
    "grid_yc_new = 235\n",
    "\n",
    "xc_old_range_min = 800\n",
    "xc_old_range_max = 320000\n",
    "yc_old_range_min = 800\n",
    "yc_old_range_max = 280000\n",
    "\n",
    "xc_new_range_min = 20000\n",
    "xc_new_range_max = 6000000\n",
    "yc_new_range_min = 20000\n",
    "yc_new_range_max = 4700000\n",
    "\n",
    "sinmod_lon_min_old = 4.316784\n",
    "sinmod_lon_max_old = 13.138062\n",
    "sinmod_lat_min_old = 62.272575\n",
    "sinmod_lat_max_old = 66.156746\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
