{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7966786b-b0e3-45ea-a094-367f4a86ae0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'get_data_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m~/PyEnvCoralMapping/lib/python3.12/site-packages/matplotlib/__init__.py:968\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[1;32m    964\u001b[0m \u001b[38;5;66;03m# When constructing the global instances, we need to perform certain updates\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;66;03m# by explicitly calling the superclass (dict.update, dict.items) to avoid\u001b[39;00m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;66;03m# triggering resolution of _auto_backend_sentinel.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m rcParamsDefault \u001b[38;5;241m=\u001b[39m _rc_params_in_file(\n\u001b[0;32m--> 968\u001b[0m     \u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmatplotlibrc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;66;03m# Strip leading comment.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m     transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m line: line[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m line,\n\u001b[1;32m    971\u001b[0m     fail_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(rcParamsDefault, rcsetup\u001b[38;5;241m.\u001b[39m_hardcoded_defaults)\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# Normally, the default matplotlibrc file contains *no* entry for backend (the\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# corresponding line starts with ##, not #; we fill on _auto_backend_sentinel\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;66;03m# in that case.  However, packagers can set a different default backend\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;66;03m# (resulting in a normal `#backend: foo` line) in which case we should *not*\u001b[39;00m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;66;03m# fill in _auto_backend_sentinel.\u001b[39;00m\n",
      "File \u001b[0;32m~/PyEnvCoralMapping/lib/python3.12/site-packages/matplotlib/cbook.py:545\u001b[0m, in \u001b[0;36m_get_data_path\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_data_path\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    540\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m    Return the `pathlib.Path` to a resource file provided by Matplotlib.\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \n\u001b[1;32m    543\u001b[0m \u001b[38;5;124;03m    ``*args`` specify a path relative to the base data path.\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Path(\u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_path\u001b[49m(), \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'get_data_path'"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bab2304d-6560-48ac-b408-7c147811bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hourly 2D bottom currents\n",
    "current_jan_jun = xr.open_dataset(\"/cluster/projects/itk-SINMOD/coral-mapping/midnor/samp_2D_jan_jun.nc\")\n",
    "current_jun_aug = xr.open_dataset(\"/cluster/projects/itk-SINMOD/coral-mapping/midnor/samp_2D_jun-aug.nc\")\n",
    "current_sep_dec = xr.open_dataset(\"/cluster/projects/itk-SINMOD/coral-mapping/midnor/samp_2D_sep-dec.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7411e9d9-696c-4af0-9ac8-37ac6dccb514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove overlap\n",
    "current_jan_jun = current_jan_jun.isel(time=slice(0, -360))  \n",
    "current_jun_aug = current_jun_aug.isel(time=slice(0, -192))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864c3e9-b099-494f-b86c-fc6de3ba13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge (not possible with this memory size.. Can do this later if necessary)\n",
    "current_2019 = xr.concat([current_jan_jun, current_jun_aug, current_sep_dec], dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a7d153-7ae9-4a7e-bc54-30bed75df611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time', 'grid_mapping', 'LayerDepths', 'xc', 'yc', 'zc', 'depth', 'DXxDYy', 'gridLats', 'gridLons', 'u_velocity', 'v_velocity', 'temperature', 'salinity', 'elevation', 'u-wind', 'v-wind', 'u-bottom', 'v-bottom', 'ice_thickness', 'ice_compactness', 'u_ice', 'v_ice', 'salinity_ice', 'ice_melt_rate', 'ice_prod_rate', 'IceVFluxX', 'IceVFluxY', 'IceAFluxX', 'IceAFluxY']\n"
     ]
    }
   ],
   "source": [
    "print(list(current_jan_jun.variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f41dfc65-70a5-4969-8484-b65f672e9705",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_vel_jan_jun = current_jan_jun.variables['u_velocity']\n",
    "u_vel_jun_aug = current_jun_aug.variables['u_velocity']\n",
    "u_vel_sep_dec = current_sep_dec.variables['u_velocity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c997d0e6-7d27-4b42-ac15-c48868b9043c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate xarray Dataset and DataArray objects, got <class 'xarray.core.variable.Variable'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m combined_u_vel \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mu_vel_jan_jun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_vel_jun_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_vel_sep_dec\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PyEnvCoralMapping/lib/python3.12/site-packages/xarray/core/concat.py:290\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs, create_index_for_new_dim)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _dataset_concat(\n\u001b[1;32m    278\u001b[0m         objs,\n\u001b[1;32m    279\u001b[0m         dim\u001b[38;5;241m=\u001b[39mdim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m         create_index_for_new_dim\u001b[38;5;241m=\u001b[39mcreate_index_for_new_dim,\n\u001b[1;32m    288\u001b[0m     )\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan only concatenate xarray Dataset and DataArray \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(first_obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate xarray Dataset and DataArray objects, got <class 'xarray.core.variable.Variable'>"
     ]
    }
   ],
   "source": [
    "combined_u_vel = xr.concat([u_vel_jan_jun, u_vel_jun_aug, u_vel_sep_dec], dim='time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88f9549d-73c1-4e47-b86c-d7f1bcf17668",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_vel_jan_jun = current_jan_jun.variables['v_velocity']\n",
    "v_vel_jun_aug = current_jun_aug.variables['v_velocity']\n",
    "v_vel_sep_dec = current_sep_dec.variables['v_velocity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b5f8315-2c99-4870-be1f-4438460e690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_vel_bottom_jan_jun = current_jan_jun.variables['u-bottom']\n",
    "u_vel_bottom_jun_aug = current_jun_aug.variables['u-bottom']\n",
    "u_vel_bottom_sep_dec = current_sep_dec.variables['u-bottom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72d0a37f-ee22-48e1-8f8a-ea7a252dcdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_vel_bottom_jan_jun = current_jan_jun.variables['v-bottom']\n",
    "v_vel_bottom_jun_aug = current_jun_aug.variables['v-bottom']\n",
    "v_vel_bottom_sep_dec = current_sep_dec.variables['v-bottom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c0561b5-8ae2-4e9f-84e0-e4c402a76f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coral data\n",
    "import pandas as pd\n",
    "\n",
    "coral_data = pd.read_parquet('/cluster/home/maikents/midnor_total_coral_data_processed_v2.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d830529c-305d-40b1-941e-ed98d0635ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram for current speed\n",
    "hor_res = current_jan_jun.grid_mapping.attrs['horizontal_resolution']\n",
    "t_start, t_stop = (0, (len(current_jan_jun.variables['time'])+len(current_jun_aug.variables['time'])+len(current_sep_dec.variables['time'])))\n",
    "coral_values = []\n",
    "valid_coords = []\n",
    "xc_max = current_jan_jun.variables['xc'].shape[0]\n",
    "yc_max = current_jan_jun.variables['yc'].shape[0]\n",
    "for time in range(t_start, t_stop):\n",
    "\n",
    "        for x, y in zip(coral_data['x']/hor_res, coral_data['y']/hor_res):\n",
    "            \n",
    "            #Ensure the coordinates are within the grid bounds\n",
    "            if 0 <= x <= xc_max and 0 <= y <= yc_max:\n",
    "\n",
    "                depth_at_point = netcdf_data.variables['depth'][int(y), int(x)]\n",
    "                layer_index = np.searchsorted(cumulative_depth, depth_at_point)\n",
    "\n",
    "                current_speed_jan_jun = np.sqrt(u_vel_jan_jun[time, layer_index, int(y), int(x)]**2 + v_vel_jan_jun[time, layer_index, int(y), int(x)]**2)\n",
    "                #value = netcdf_data.variables[variable_name][time, layer_index, int(y), int(x)]\n",
    "\n",
    "                if not np.ma.is_masked(value):\n",
    "                    coral_values.append(value)\n",
    "                    if (x, y) not in valid_coordinates:\n",
    "                        valid_coordinates.append((x, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83755846-31c2-43e2-a362-29eee2c71da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot histograms\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_histogram_at_coral_points(netcdf_data, coral_data, variable_name, t_range, generate_random=False, save=False, save_path=\"midnor\"):\n",
    "\n",
    "    zc = netcdf_data.variables['LayerDepths'][:]\n",
    "    cumulative_depth = np.cumsum(zc, axis=0)\n",
    "\n",
    "    xc_max = netcdf_data.variables['xc'].shape[0]\n",
    "    yc_max = netcdf_data.variables['yc'].shape[0]\n",
    "\n",
    "    hor_res = netcdf_data.variables['grid_mapping'].getncattr('horizontal_resolution')\n",
    "\n",
    "    t_start, t_stop = t_range\n",
    "\n",
    "    if t_stop == -1:\n",
    "        t_stop = netcdf_data.variables['time'].shape[0]\n",
    "\n",
    "    # Extract variable values at coral data points\n",
    "    coral_values = []\n",
    "    valid_coordinates = []\n",
    "\n",
    "    for time in range(t_start, t_stop):\n",
    "\n",
    "        for x, y in zip(coral_data['x']/hor_res, coral_data['y']/hor_res):\n",
    "            \n",
    "            # Ensure the coordinates are within the grid bounds\n",
    "            if 0 <= x <= xc_max and 0 <= y <= yc_max:\n",
    "\n",
    "                depth_at_point = netcdf_data.variables['depth'][int(y), int(x)]\n",
    "                layer_index = np.searchsorted(cumulative_depth, depth_at_point)\n",
    "\n",
    "                if variable_name == 'current_speed':\n",
    "                    value = np.sqrt(netcdf_data.variables['u_velocity'][time, layer_index, int(y), int(x)]**2 + netcdf_data.variables['v_velocity'][time, layer_index, int(y), int(x)]**2)\n",
    "                else:\n",
    "                    value = netcdf_data.variables[variable_name][time, layer_index, int(y), int(x)]\n",
    "\n",
    "                if not np.ma.is_masked(value):\n",
    "                    coral_values.append(value)\n",
    "                    if (x, y) not in valid_coordinates:\n",
    "                        valid_coordinates.append((x, y))\n",
    "\n",
    "    # Convert list to numpy array for easier manipulation\n",
    "    coral_values = np.array(coral_values)\n",
    "\n",
    "    # Flatten the array to combine all time steps\n",
    "    coral_values_flat = coral_values.flatten()\n",
    "\n",
    "    # Calculate statistics for coral values\n",
    "    stats = {\n",
    "        'mean': np.mean(coral_values_flat),\n",
    "        'max': np.max(coral_values_flat),\n",
    "        'min': np.min(coral_values_flat),\n",
    "        '90th_percentile': np.percentile(coral_values_flat, 90),\n",
    "        '10th_percentile': np.percentile(coral_values_flat, 10)\n",
    "    }\n",
    "\n",
    "    print(f\"Statistics for coral values: {stats}\")\n",
    "\n",
    "    # Determine the bin edges for the histograms\n",
    "    bin_edges = np.histogram_bin_edges(coral_values_flat, bins=20)\n",
    "\n",
    "    # Plot histogram of the combined variable values\n",
    "    plt.hist(coral_values_flat, bins=bin_edges, edgecolor='black')\n",
    "    plt.xlabel(f'{variable_name.capitalize()}')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Histogram of {variable_name.capitalize()} at Coral Data Points - {save_path.capitalize()}')\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f'plots/variable_histograms/{variable_name}_histogram_coral_points_{save_path}.png')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Number of valid coordinates: {len(valid_coordinates)} out of {len(coral_data)}\")\n",
    "\n",
    "    if generate_random:\n",
    "        # Plotting random histogram\n",
    "\n",
    "        no_points = int(len(valid_coordinates))\n",
    "\n",
    "        # Generate same number of valid co-ords as random x and y locations within the grid\n",
    "        valid_xc_yc_indices = np.argwhere(np.logical_and(~netcdf_data.variables['temperature'][0,0].mask, netcdf_data.variables['depth'][:] <=275,  netcdf_data.variables['depth'][:] >= 150))\n",
    "\n",
    "        random_values = []\n",
    "\n",
    "        for time in range(t_start, t_stop):\n",
    "\n",
    "            selected_indices = valid_xc_yc_indices[np.random.choice(valid_xc_yc_indices.shape[0], size=no_points, replace=False)]\n",
    "\n",
    "            for y, x in selected_indices:\n",
    "                \n",
    "                # Ensure the coordinates are within the grid bounds\n",
    "                if 0 <= x <= xc_max and 0 <= y <= yc_max:\n",
    "                    depth_at_point = netcdf_data.variables['depth'][int(y), int(x)]\n",
    "                    layer_index = np.searchsorted(cumulative_depth, depth_at_point)\n",
    "\n",
    "                    if variable_name == 'current_speed':\n",
    "                        value = np.sqrt(netcdf_data.variables['u_velocity'][time, layer_index, int(y), int(x)]**2 + netcdf_data.variables['v_velocity'][time, layer_index, int(y), int(x)]**2)\n",
    "                    else:\n",
    "                        value = netcdf_data.variables[variable_name][time, layer_index, int(y), int(x)]\n",
    "\n",
    "                    if not np.ma.is_masked(value):\n",
    "                        random_values.append(value)\n",
    "        \n",
    "        # Convert list to numpy array for easier manipulation\n",
    "        random_values = np.array(random_values)\n",
    "\n",
    "        # Flatten the array to combine all time steps\n",
    "        random_values_flat = random_values.flatten()\n",
    "\n",
    "        # Plot histogram of the combined random variable values\n",
    "        plt.hist(random_values_flat, bins=bin_edges, edgecolor='black')\n",
    "        plt.xlabel(f'Random {variable_name.capitalize()}')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title(f'Histogram of Random {variable_name.capitalize()} Values - {save_path.capitalize()}')\n",
    "        \n",
    "        if save:\n",
    "            plt.savefig(f'plots/variable_histograms/{variable_name}_histogram_coral_points_{save_path}_random.png')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        random_stats = {\n",
    "            'mean': np.mean(random_values_flat),\n",
    "            'max': np.max(random_values_flat),\n",
    "            'min': np.min(random_values_flat),\n",
    "            '90th_percentile': np.percentile(random_values_flat, 90),\n",
    "            '10th_percentile': np.percentile(random_values_flat, 10)\n",
    "        }\n",
    "\n",
    "        print(f\"Statistics for random values: {random_stats}\")\n",
    "\n",
    "        return coral_values, stats, random_values, random_stats\n",
    "    return coral_values, stats\n",
    "\n",
    "# Example usage\n",
    "# plot_histogram_at_coral_points(PhysStates_data, coral_data, 'temperature', (0, 50))\n",
    "# plot_histogram_at_coral_points(nor4km_PhysStates_data, nor4km_coral_data, 'temperature', (0, 50))\n",
    "midnor_temp, midnor_stats, midnor_temp_random, midnor_random_stats = plot_histogram_at_coral_points(midnor_PhysStates_data, midnor_coral_data, 'temperature', (0, 10), True)\n",
    "# plot_histogram_at_coral_points(midnor_PhysStates_data, midnor_coral_data, 'salinity', (0, 50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
