{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7966786b-b0e3-45ea-a094-367f4a86ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab2304d-6560-48ac-b408-7c147811bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hourly 2D bottom currents\n",
    "jan_jun = xr.open_dataset(\"/cluster/projects/itk-SINMOD/coral-mapping/midnor/samp_2D_jan_jun.nc\")\n",
    "jun_aug = xr.open_dataset(\"/cluster/projects/itk-SINMOD/coral-mapping/midnor/samp_2D_jun-aug.nc\")\n",
    "sep_dec = xr.open_dataset(\"/cluster/projects/itk-SINMOD/coral-mapping/midnor/samp_2D_sep-dec.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411e9d9-696c-4af0-9ac8-37ac6dccb514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove overlap\n",
    "jan_jun = jan_jun.isel(time=slice(0, -360))  \n",
    "jun_aug = jun_aug.isel(time=slice(0, -192))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864c3e9-b099-494f-b86c-fc6de3ba13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge (not possible with this memory size.. Can do this later if necessary)\n",
    "current_2019 = xr.concat([current_jan_jun, current_jun_aug, current_sep_dec], dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7d153-7ae9-4a7e-bc54-30bed75df611",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(jan_jun.variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07e90e21-46e8-4dfe-9056-beabbc728d0c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "u_bottom_jan_jun = jan_jun.variables['u-bottom']\n",
    "u_bottom_jun_aug = jun_aug.variables['u-bottom']\n",
    "u_bottom_sep_dec = sep_dec.variables['u-bottom']\n",
    "v_bottom_jan_jun = jan_jun.variables['v-bottom']\n",
    "v_bottom_jun_aug = jun_aug.variables['v-bottom']\n",
    "v_bottom_sep_dec = sep_dec.variables['v-bottom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00c47538-327c-4cd8-822a-eca3cdcf5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_bottom_jan_jun = xr.DataArray(u_bottom_jan_jun)\n",
    "u_bottom_jun_aug = xr.DataArray(u_bottom_jun_aug)\n",
    "u_bottom_sep_dec = xr.DataArray(u_bottom_sep_dec)\n",
    "v_bottom_jan_jun = xr.DataArray(v_bottom_jan_jun)\n",
    "v_bottom_jun_aug = xr.DataArray(v_bottom_jun_aug)\n",
    "v_bottom_sep_dec = xr.DataArray(v_bottom_sep_dec)\n",
    "\n",
    "#Combine\n",
    "u_bottom_2019 = xr.concat([u_bottom_jan_jun, u_bottom_jun_aug, u_bottom_sep_dec], dim='time')\n",
    "v_bottom_2019 = xr.concat([v_bottom_jan_jun, v_bottom_jun_aug, v_bottom_sep_dec], dim='time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24ef18e6-6421-47df-916a-0a643caa136d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "output_path = \"/cluster/home/maikents/bottom_currents_2019.nc\"\n",
    "\n",
    "bottom_currents = xr.Dataset({\n",
    "    \"u_bottom\": u_bottom_2019,\n",
    "    \"v_bottom\": v_bottom_2019\n",
    "})\n",
    "\n",
    "bottom_currents.to_netcdf(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0561b5-8ae2-4e9f-84e0-e4c402a76f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coral data\n",
    "import pandas as pd\n",
    "\n",
    "coral_data = pd.read_parquet('/cluster/home/maikents/midnor_total_coral_data_processed_v2.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf524b-16fc-469d-89f2-eeb5fc457e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"xc_max: {xc_max}, yc_max: {yc_max}\")\n",
    "print(f\"Max x in coral data: {max(coral_data['x']/hor_res)}, Max y: {max(coral_data['y']/hor_res)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d830529c-305d-40b1-941e-ed98d0635ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram for bottom current speed\n",
    "hor_res = jan_jun.grid_mapping.attrs['horizontal_resolution']\n",
    "t_start, t_stop = (0, len(u_bottom_2019))\n",
    "coral_values_jan_jun = []\n",
    "valid_coords_jan_jun = []\n",
    "xc_max = jan_jun.variables['xc'].shape[0]\n",
    "yc_max = jan_jun.variables['yc'].shape[0]\n",
    "for time in range(t_start, t_stop):\n",
    "\n",
    "        for x, y in zip(coral_data['x']/hor_res, coral_data['y']/hor_res):\n",
    "            x = np.clip(np.round(coral_data['x']/hor_res).astype(int), 0, xc_max-1)\n",
    "            y = np.clip(np.round(coral_data['y']/hor_res).astype(int), 0, yc_max-1)\n",
    "            value = np.sqrt(jan_jun.variables['u-bottom'][time, y, x]**2 + jan_jun.variables['v-bottom'][time, y, x]**2)\n",
    "            if not np.ma.is_masked(value):\n",
    "                coral_values_jan_jun.append(value)\n",
    "    \n",
    "                        \n",
    "#Convert list to numpy array for easier manipulation\n",
    "coral_values_jan_jun = np.array(coral_values_jan_jun)\n",
    "\n",
    "#Flatten the array to combine all time steps\n",
    "coral_values_jan_jun_flat = coral_values_jan_jun.flatten()\n",
    "\n",
    "# Calculate statistics for coral values\n",
    "stats_jan_jun = {\n",
    "    'mean': np.mean(coral_values_flat_jan_jun),\n",
    "    'max': np.max(coral_values_flat_jan_jun),\n",
    "    'min': np.min(coral_values_flat_jan_jun),\n",
    "    '90th_percentile': np.percentile(coral_values_flat_jann_jun, 90),\n",
    "    '10th_percentile': np.percentile(coral_values_flat, 10)\n",
    "}\n",
    "\n",
    "print(f\"Statistics for coral values: {stats_jan_jun}\")\n",
    "\n",
    "#Determine the bin edges for the histograms\n",
    "bin_edges = np.histogram_bin_edges(coral_values_flat_jan_jun, bins=20)\n",
    "\n",
    "#Plot histogram of the combined variable values\n",
    "plt.hist(coral_values_flat_jan_jun, bins=bin_edges, edgecolor='black')\n",
    "plt.xlabel('Current speed [m/s]', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.title(f'Histogram of current speeds at coral data points', fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.savefig(f'/cluster/home/maikents/current_speed_histogram_coral_points_jan_jun.png')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a72055-5724-4c15-89ef-c344713fc2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "          \"\"\"\n",
    "            #Ensure the coordinates are within the grid bounds\n",
    "            if 0 <= x <= xc_max and 0 <= y <= yc_max:\n",
    "                #value = np.sqrt(u_bottom_2019[time, x, y]**2 + v_bottom_2019[time, x, y]**2)\n",
    "                #value = np.sqrt(u_bottom_2019.isel(xc=int(x), yc=int(y), time=time)**2 +v_bottom_2019.isel(xc=int(x), yc=int(y), time=time)**2)                #value = netcdf_data.variables[variable_name][time, layer_index, int(y), int(x)]\n",
    "                value = np.sqrt(jan_jun.variables['u-bottom'][time, int(y), int(x)]**2 + jan_jun.variables['v-bottom'][time, int(y), int(x)]**2)\n",
    "\"\"\"\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83755846-31c2-43e2-a362-29eee2c71da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot histograms\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_histogram_at_coral_points(netcdf_data, coral_data, variable_name, t_range, generate_random=False, save=False, save_path=\"midnor\"):\n",
    "\n",
    "    zc = netcdf_data.variables['LayerDepths'][:]\n",
    "    cumulative_depth = np.cumsum(zc, axis=0)\n",
    "\n",
    "    xc_max = netcdf_data.variables['xc'].shape[0]\n",
    "    yc_max = netcdf_data.variables['yc'].shape[0]\n",
    "\n",
    "    hor_res = netcdf_data.variables['grid_mapping'].getncattr('horizontal_resolution')\n",
    "\n",
    "    t_start, t_stop = t_range\n",
    "\n",
    "    if t_stop == -1:\n",
    "        t_stop = netcdf_data.variables['time'].shape[0]\n",
    "\n",
    "    # Extract variable values at coral data points\n",
    "    coral_values = []\n",
    "    valid_coordinates = []\n",
    "\n",
    "    for time in range(t_start, t_stop):\n",
    "\n",
    "        for x, y in zip(coral_data['x']/hor_res, coral_data['y']/hor_res):\n",
    "            \n",
    "            # Ensure the coordinates are within the grid bounds\n",
    "            if 0 <= x <= xc_max and 0 <= y <= yc_max:\n",
    "\n",
    "                depth_at_point = netcdf_data.variables['depth'][int(y), int(x)]\n",
    "                layer_index = np.searchsorted(cumulative_depth, depth_at_point)\n",
    "\n",
    "                if variable_name == 'current_speed':\n",
    "                    value = np.sqrt(netcdf_data.variables['u_velocity'][time, layer_index, int(y), int(x)]**2 + netcdf_data.variables['v_velocity'][time, layer_index, int(y), int(x)]**2)\n",
    "                else:\n",
    "                    value = netcdf_data.variables[variable_name][time, layer_index, int(y), int(x)]\n",
    "\n",
    "                if not np.ma.is_masked(value):\n",
    "                    coral_values.append(value)\n",
    "                    if (x, y) not in valid_coordinates:\n",
    "                        valid_coordinates.append((x, y))\n",
    "\n",
    "    # Convert list to numpy array for easier manipulation\n",
    "    coral_values = np.array(coral_values)\n",
    "\n",
    "    # Flatten the array to combine all time steps\n",
    "    coral_values_flat = coral_values.flatten()\n",
    "\n",
    "    # Calculate statistics for coral values\n",
    "    stats = {\n",
    "        'mean': np.mean(coral_values_flat),\n",
    "        'max': np.max(coral_values_flat),\n",
    "        'min': np.min(coral_values_flat),\n",
    "        '90th_percentile': np.percentile(coral_values_flat, 90),\n",
    "        '10th_percentile': np.percentile(coral_values_flat, 10)\n",
    "    }\n",
    "\n",
    "    print(f\"Statistics for coral values: {stats}\")\n",
    "\n",
    "    # Determine the bin edges for the histograms\n",
    "    bin_edges = np.histogram_bin_edges(coral_values_flat, bins=20)\n",
    "\n",
    "    # Plot histogram of the combined variable values\n",
    "    plt.hist(coral_values_flat, bins=bin_edges, edgecolor='black')\n",
    "    plt.xlabel(f'{variable_name.capitalize()}')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Histogram of {variable_name.capitalize()} at Coral Data Points - {save_path.capitalize()}')\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f'plots/variable_histograms/{variable_name}_histogram_coral_points_{save_path}.png')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Number of valid coordinates: {len(valid_coordinates)} out of {len(coral_data)}\")\n",
    "\n",
    "    if generate_random:\n",
    "        # Plotting random histogram\n",
    "\n",
    "        no_points = int(len(valid_coordinates))\n",
    "\n",
    "        # Generate same number of valid co-ords as random x and y locations within the grid\n",
    "        valid_xc_yc_indices = np.argwhere(np.logical_and(~netcdf_data.variables['temperature'][0,0].mask, netcdf_data.variables['depth'][:] <=275,  netcdf_data.variables['depth'][:] >= 150))\n",
    "\n",
    "        random_values = []\n",
    "\n",
    "        for time in range(t_start, t_stop):\n",
    "\n",
    "            selected_indices = valid_xc_yc_indices[np.random.choice(valid_xc_yc_indices.shape[0], size=no_points, replace=False)]\n",
    "\n",
    "            for y, x in selected_indices:\n",
    "                \n",
    "                # Ensure the coordinates are within the grid bounds\n",
    "                if 0 <= x <= xc_max and 0 <= y <= yc_max:\n",
    "                    depth_at_point = netcdf_data.variables['depth'][int(y), int(x)]\n",
    "                    layer_index = np.searchsorted(cumulative_depth, depth_at_point)\n",
    "\n",
    "                    if variable_name == 'current_speed':\n",
    "                        value = np.sqrt(netcdf_data.variables['u_velocity'][time, layer_index, int(y), int(x)]**2 + netcdf_data.variables['v_velocity'][time, layer_index, int(y), int(x)]**2)\n",
    "                    else:\n",
    "                        value = netcdf_data.variables[variable_name][time, layer_index, int(y), int(x)]\n",
    "\n",
    "                    if not np.ma.is_masked(value):\n",
    "                        random_values.append(value)\n",
    "        \n",
    "        # Convert list to numpy array for easier manipulation\n",
    "        random_values = np.array(random_values)\n",
    "\n",
    "        # Flatten the array to combine all time steps\n",
    "        random_values_flat = random_values.flatten()\n",
    "\n",
    "        # Plot histogram of the combined random variable values\n",
    "        plt.hist(random_values_flat, bins=bin_edges, edgecolor='black')\n",
    "        plt.xlabel(f'Random {variable_name.capitalize()}')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title(f'Histogram of Random {variable_name.capitalize()} Values - {save_path.capitalize()}')\n",
    "        \n",
    "        if save:\n",
    "            plt.savefig(f'plots/variable_histograms/{variable_name}_histogram_coral_points_{save_path}_random.png')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        random_stats = {\n",
    "            'mean': np.mean(random_values_flat),\n",
    "            'max': np.max(random_values_flat),\n",
    "            'min': np.min(random_values_flat),\n",
    "            '90th_percentile': np.percentile(random_values_flat, 90),\n",
    "            '10th_percentile': np.percentile(random_values_flat, 10)\n",
    "        }\n",
    "\n",
    "        print(f\"Statistics for random values: {random_stats}\")\n",
    "\n",
    "        return coral_values, stats, random_values, random_stats\n",
    "    return coral_values, stats\n",
    "\n",
    "# Example usage\n",
    "# plot_histogram_at_coral_points(PhysStates_data, coral_data, 'temperature', (0, 50))\n",
    "# plot_histogram_at_coral_points(nor4km_PhysStates_data, nor4km_coral_data, 'temperature', (0, 50))\n",
    "midnor_temp, midnor_stats, midnor_temp_random, midnor_random_stats = plot_histogram_at_coral_points(midnor_PhysStates_data, midnor_coral_data, 'temperature', (0, 10), True)\n",
    "# plot_histogram_at_coral_points(midnor_PhysStates_data, midnor_coral_data, 'salinity', (0, 50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
