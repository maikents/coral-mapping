{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b5743fdb-6116-4aba-8de1-2cc4ebe8da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import elapid\n",
    "from elapid import MaxentModel\n",
    "import xarray as xr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import elapid\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c0dcacc0-091a-4f24-99da-44f76d988653",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = '/cluster/home/maikents/coral-mapping/processed_data/df_ready_for_training.parquet'\n",
    "df = pd.read_parquet(data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8932f69c-4166-4217-839f-7170a77af81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x', 'y', 'bottom_statistical_northness_features',\n",
      "       'bottom_statistical_eastness_features', 'current_aspect_angle',\n",
      "       'bottom_salinity_features_mean', 'bottom_current_features_mean',\n",
      "       'bottom_temperature_features_10th_percentile', 'label',\n",
      "       'aspect_cos_clipped', 'aspect_sin_clipped',\n",
      "       'bathymetry_32N_Clip_sample_clipped', 'broad_BPI_std_clipped',\n",
      "       'fine_BPI_std_clipped', 'slope_clipped'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a8d76427-102b-49e3-9fcc-a68a58a3bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "absence_df = df[df['label'] == 0]\n",
    "downsampled_absences = absence_df.sample(n=2000, random_state=42)\n",
    "\n",
    "presence_df = df[df['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "806d75f1-01a9-48d1-b207-ef90dd94e7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x', 'y', 'bottom_statistical_northness_features',\n",
      "       'bottom_statistical_eastness_features', 'current_aspect_angle',\n",
      "       'bottom_salinity_features_mean', 'bottom_current_features_mean',\n",
      "       'bottom_temperature_features_10th_percentile', 'label',\n",
      "       'aspect_cos_clipped', 'aspect_sin_clipped',\n",
      "       'bathymetry_32N_Clip_sample_clipped', 'broad_BPI_std_clipped',\n",
      "       'fine_BPI_std_clipped', 'slope_clipped'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "balanced_df = pd.concat([downsampled_absences, presence_df])\n",
    "print(balanced_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6d38b2da-71c7-4ac4-a43e-a8d3d7c037e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define features and labels\n",
    "X = balanced_df.drop(columns=['label', 'x', 'y'])  #Drop label and coordinates\n",
    "y = balanced_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "37fcc529-dd04-4fdc-bceb-80c8de69ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "735354ad-53d8-4114-b3e5-01b46506eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize MaxEnt model\n",
    "model = elapid.MaxentModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "34a0ec4b-1c32-498e-9f8c-d92bb09694ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up K fold cross validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "2381d88c-19ea-42d7-8c48-ba2e57eaf1ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/maikents/PyEnvCoralMapping/lib/python3.12/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n",
      "/cluster/home/maikents/PyEnvCoralMapping/lib/python3.12/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n",
      "/cluster/home/maikents/PyEnvCoralMapping/lib/python3.12/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n",
      "/cluster/home/maikents/PyEnvCoralMapping/lib/python3.12/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n",
      "/cluster/home/maikents/PyEnvCoralMapping/lib/python3.12/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n",
      "/cluster/home/maikents/PyEnvCoralMapping/lib/python3.12/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n",
      "/cluster/home/maikents/PyEnvCoralMapping/lib/python3.12/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n",
      "/cluster/home/maikents/PyEnvCoralMapping/lib/python3.12/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n",
      "/cluster/home/maikents/PyEnvCoralMapping/lib/python3.12/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n",
      "/cluster/home/maikents/PyEnvCoralMapping/lib/python3.12/site-packages/elapid/features.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x.drop([\"geometry\"], axis=1, errors=\"ignore\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC: 0.9590\n",
      "Average F1: 0.8004\n",
      "Average Precison: 0.8431\n",
      "Average Recall: 0.7639\n",
      "Average balanced accuracy score: 0.8562\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "auc_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "balanced_accuracy_scores = []\n",
    "\n",
    "# Loop through each cross-validation fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Initialize the MaxEnt model\n",
    "    model = elapid.MaxentModel(transform='cloglog'#,\n",
    "                               #beta_multiplier=4.0,     #adjusts regularization scale\n",
    "                               #beta_hinge = 3.0,        #controls hinge regularization\n",
    "                               #beta_threshold = 1.0    #applies to threshold regularization\n",
    "    )\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred = model.predict(X_test_cv)\n",
    "    y_test_pred_labels = (y_pred > 0.5).astype(int)  # Convert probabilities to binary labels\n",
    "\n",
    "    \n",
    "\n",
    "    # Evaluate the model using AUC score\n",
    "\n",
    "    auc_elapid = metrics.roc_auc_score(y_test_cv, y_pred)\n",
    "    auc_scores.append(auc_elapid)\n",
    "\n",
    "    f1 = metrics.f1_score(y_test_cv, y_test_pred_labels)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    precision = metrics.precision_score(y_test_cv, y_test_pred_labels)\n",
    "    precision_scores.append(precision)    \n",
    "    \n",
    "    recall = metrics.recall_score(y_test_cv, y_test_pred_labels)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "    balanced_accuracy_score = metrics.balanced_accuracy_score(y_test_cv, y_test_pred_labels)\n",
    "    balanced_accuracy_scores.append(balanced_accuracy_score)\n",
    "\n",
    "\n",
    "    # Optionally, calculate accuracy\n",
    "    #accuracy = accuracy_score(y_test_cv, y_pred)\n",
    "    #scores.append(accuracy)\n",
    "\n",
    "# Calculate the average AUC and accuracy across all folds\n",
    "avg_auc = sum(auc_scores) / len(auc_scores)\n",
    "avg_f1 = sum(f1_scores) / len(f1_scores)\n",
    "avg_recall = sum(recall_scores) / len(recall_scores)\n",
    "avg_precision = sum(precision_scores) / len(precision_scores)\n",
    "avg_balanced_accuracy = sum(balanced_accuracy_scores) / len(balanced_accuracy_scores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Average AUC: {avg_auc:.4f}\")\n",
    "print(f\"Average F1: {avg_f1:.4f}\")\n",
    "print(f\"Average Precison: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average balanced accuracy score: {avg_balanced_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "bd3d0d2b-a54e-4be3-8a4f-ae1ffeae902e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC score: 0.957\n",
      "Test F1 score: 0.772\n",
      "Test precision score: 0.824\n",
      "Test recall score: 0.725\n",
      "Balanced accuracy score: 0.835\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the full training data\n",
    "model = elapid.MaxentModel(transform='cloglog', beta_multiplier=2.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_labels = (y_test_pred > 0.5).astype(int)  # Convert probabilities to binary labels\n",
    "\n",
    "\n",
    "# Evaluate using accuracy and AUC\n",
    "auc_elapid = metrics.roc_auc_score(y_test, y_test_pred)\n",
    "f1 = metrics.f1_score(y_test, y_test_pred_labels)\n",
    "precision = metrics.precision_score(y_test, y_test_pred_labels)\n",
    "recall = metrics.recall_score(y_test, y_test_pred_labels)\n",
    "balanced_accuracy = metrics.balanced_accuracy_score(y_test, y_test_pred_labels)\n",
    "\n",
    "\n",
    "print(f\"Test AUC score: {auc_elapid:0.3f}\")\n",
    "print(f\"Test F1 score: {f1:0.3f}\")\n",
    "print(f\"Test precision score: {precision:0.3f}\")\n",
    "print(f\"Test recall score: {recall:0.3f}\")\n",
    "print(f\"Balanced accuracy score: {balanced_accuracy:0.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "5649266b-1a02-40d4-9832-9914c950ed63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC score: 0.958\n",
      "Test F1 score: 0.779\n",
      "Test precision score: 0.832\n",
      "Test recall score: 0.732\n",
      "Balanced accuracy score: 0.840\n"
     ]
    }
   ],
   "source": [
    "#Regularization tuning\n",
    "\n",
    "model = elapid.MaxentModel(\n",
    "    transform='cloglog',\n",
    "    beta_multiplier=4.0,     #adjusts regularization scale\n",
    "    beta_hinge = 3.0,        #controls hinge regularization\n",
    "    beta_threshold = 1.0    #applies to threshold regularization\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_labels = (y_test_pred > 0.5).astype(int)  # Convert probabilities to binary labels\n",
    "\n",
    "\n",
    "# Evaluate using accuracy and AUC\n",
    "auc_elapid = metrics.roc_auc_score(y_test, y_test_pred)\n",
    "f1 = metrics.f1_score(y_test, y_test_pred_labels)\n",
    "precision = metrics.precision_score(y_test, y_test_pred_labels)\n",
    "recall = metrics.recall_score(y_test, y_test_pred_labels)\n",
    "balanced_accuracy = metrics.balanced_accuracy_score(y_test, y_test_pred_labels)\n",
    "\n",
    "\n",
    "print(f\"Test AUC score: {auc_elapid:0.3f}\")\n",
    "print(f\"Test F1 score: {f1:0.3f}\")\n",
    "print(f\"Test precision score: {precision:0.3f}\")\n",
    "print(f\"Test recall score: {recall:0.3f}\")\n",
    "print(f\"Balanced accuracy score: {balanced_accuracy:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f0233-d3c8-4da0-8855-5f2b0c92075f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
